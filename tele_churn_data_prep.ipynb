{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plot\n",
    "from ydata_profiling import ProfileReport\n",
    "import scipy.stats as stats\n",
    "import seaborn\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFile = r'churn_raw_data.csv'\n",
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.read_csv(csvFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Data Using Profile Report Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(df, title=\"Profile Report\")\n",
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Duplicate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Total Duplicate Values in Dataset\n",
    "listTotal = 0\n",
    "for column_name in df.columns:\n",
    "    listTotal = df[column_name].duplicated().sum() + listTotal\n",
    "print(listTotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Duplicate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect duplicate values\n",
    "# Finding total duplicate values in each column\n",
    "for column_name in df.columns:\n",
    "    print(column_name)\n",
    "    print(df[column_name].duplicated().sum())\n",
    "    print(\"==================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting and Removing Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find total NULL values for each column in dataset \n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph columns to see distribution of data.\n",
    "# Depending on distribution of data different imputation methods will be used.\n",
    "# Columns to graph Children, Age, Income, Techie, InternetService, Phone, TechSupport, Tenure, Bandwidth_GB_Year.\n",
    "plot.figure()\n",
    "plot.title('Children')\n",
    "plot.hist(df['Children'])\n",
    "\n",
    "plot.figure()\n",
    "plot.title('Age')\n",
    "plot.hist(df['Age'])\n",
    "\n",
    "plot.figure()\n",
    "plot.title('Income')\n",
    "plot.hist(df['Income'])\n",
    "\n",
    "plot.figure()\n",
    "plot.title('Tenure')\n",
    "plot.hist(df['Tenure'])\n",
    "\n",
    "plot.figure()\n",
    "plot.title('Bandwidth_GB_Year')\n",
    "plot.hist(df['Bandwidth_GB_Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Mode in categorical data with NULL values\n",
    "print(df['Techie'].mode())\n",
    "print(df[\"InternetService\"].mode())\n",
    "print(df[\"Phone\"].mode())\n",
    "print(df[\"TechSupport\"].mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Null values\n",
    "\n",
    "# Numeric\n",
    "df['Children'].fillna(df['Children'].median(), inplace=True)\n",
    "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "df['Income'].fillna(df['Income'].median(), inplace=True)\n",
    "df[\"Tenure\"].fillna(df['Tenure'].median(),inplace=True)\n",
    "df[\"Bandwidth_GB_Year\"].fillna(df['Bandwidth_GB_Year'].median(),inplace=True)\n",
    "\n",
    "# Categorical \n",
    "df['Techie'].fillna('No', inplace=True)\n",
    "df[\"InternetService\"].fillna('Fiber Optic',inplace=True)\n",
    "df[\"Phone\"].fillna('Yes',inplace=True)\n",
    "df[\"TechSupport\"].fillna('No',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NULL values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect and Remove Outliers in Quantitative and Qualitative Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing qualitative data for innapropriate data points / Outliers\n",
    "qualOutliers = ['Unnamed: 0','CaseOrder','Customer_id','Interaction','City', \n",
    "                'State','County','Zip','Lat','Lng','Area',\n",
    "                'Timezone','Job','Education','Employment','Marital',\n",
    "                'Gender','Churn','Techie','Contract','Port_modem'\n",
    "                ,'Tablet','InternetService','Phone','Multiple','OnlineSecurity'\n",
    "                ,'OnlineBackup','DeviceProtection','TechSupport', 'StreamingTV', 'StreamingMovies'\n",
    "                ,'PaperlessBilling','PaymentMethod','item1', 'item2','item3','item4'\n",
    "                ,'item5','item6','item7','item8']\n",
    "\n",
    "for columnName in qualOutliers:\n",
    "        print(columnName.upper())                                                       # Make upper case for readability\n",
    "        print(str(df[columnName].unique()) + \" , Number Unique Items: \" + str(df[columnName].nunique()))\n",
    "        print(\"===============================\")                                        # Divide output for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing quantitative data for outliers\n",
    "# When using z-score values +-3 are considered outliers\n",
    "quantOutliers = df.columns\n",
    "zscore_df = pd.DataFrame()\n",
    "\n",
    "quantOutliers = [column for column in quantOutliers if column not in qualOutliers]\n",
    "\n",
    "for column in quantOutliers:\n",
    "    #zscore_df[f'{column}'] = df[f'{column}']\n",
    "    zscore_df[f'Z Score {column}'] = stats.zscore(df[column])\n",
    "\n",
    "for column in zscore_df:\n",
    "    plot.figure()\n",
    "    zscore_df.hist([column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Box plot of each column to visualize outliers in data\n",
    "for column in zscore_df:\n",
    "    plot.figure()\n",
    "    zscore_df.boxplot([column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter through zscore dataframe to find number of rows that are > 3\n",
    "for column in zscore_df:\n",
    "    print(zscore_df.loc[zscore_df[column] > 3, [column]].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the columns with outlier to see if those outliers are reasonable\n",
    "for column in quantOutliers:\n",
    "    print(column)\n",
    "    print(f\"Max: {df[column].max()} Min: {df[column].min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers from 'Outage_sec_perweek' column\n",
    "df.loc[df['Outage_sec_perweek'] < 0, ['Outage_sec_perweek']]\n",
    "df[df['Outage_sec_perweek'] < 0] = df['Outage_sec_perweek'].median()\n",
    "df.loc[df['Outage_sec_perweek'] < 0, ['Outage_sec_perweek']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if outliers from Outage_sec_perweek were removed\n",
    "df['Outage_sec_perweek'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Nominal / Ordinal Encoding to Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing columns that need to be encoded\n",
    "df[[\"Gender\",\"Churn\",\"Techie\",\"Port_modem\",\"Tablet\",\"Phone\",\"Multiple\",\"OnlineBackup\",\n",
    "\"OnlineSecurity\",\"DeviceProtection\",\"TechSupport\",\"StreamingTV\",\"StreamingMovies\",\"PaperlessBilling\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Norminal / Ordinal Encoding\n",
    "# Example columns: df['Churn'] and df['Gender']\n",
    "# Categorical columns that wont be changed: Area, Employment, Marital, Contract\n",
    "nominalGender = {\n",
    "    \"Male\": 0\n",
    "    ,\"Female\": 1\n",
    "}\n",
    "nominalYN = {\n",
    "    \"Yes\": 1\n",
    "    ,\"No\": 0\n",
    "}\n",
    "\n",
    "df[\"Gender\"].replace(nominalGender, inplace=True)\n",
    "df[\"Churn\"].replace(nominalYN, inplace=True)\n",
    "df[\"Techie\"].replace(nominalYN, inplace=True)\n",
    "df[\"Port_modem\"].replace(nominalYN, inplace=True)\n",
    "df[\"Tablet\"].replace(nominalYN, inplace=True)\n",
    "df[\"Phone\"].replace(nominalYN, inplace=True)\n",
    "df[\"Multiple\"].replace(nominalYN, inplace=True)\n",
    "df[\"OnlineBackup\"].replace(nominalYN, inplace=True)\n",
    "df[\"OnlineSecurity\"].replace(nominalYN, inplace=True)\n",
    "df[\"DeviceProtection\"].replace(nominalYN, inplace=True)\n",
    "df[\"TechSupport\"].replace(nominalYN, inplace=True)\n",
    "df[\"StreamingTV\"].replace(nominalYN, inplace=True)\n",
    "df[\"StreamingMovies\"].replace(nominalYN, inplace=True)\n",
    "df[\"PaperlessBilling\"].replace(nominalYN, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if columns were properly encoded\n",
    "df[[\"Gender\",\"Churn\",\"Techie\",\"Port_modem\",\"Tablet\",\"Phone\",\"Multiple\",\"OnlineBackup\",\n",
    "\"OnlineSecurity\",\"DeviceProtection\",\"TechSupport\",\"StreamingTV\",\"StreamingMovies\",\"PaperlessBilling\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primare Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List variables used in PCA\n",
    "list=[]\n",
    "nonList = ['Unnamed: 0','CaseOrder','Customer_id','Interaction','City', \n",
    "                'State','County','Zip','Lat','Lng','Area',\n",
    "                'Timezone','Job','Education','Employment','Marital',\n",
    "                'Gender','Churn','Techie','Contract','Port_modem'\n",
    "                ,'Tablet','InternetService','Phone','Multiple','OnlineSecurity'\n",
    "                ,'OnlineBackup','DeviceProtection','TechSupport', 'StreamingTV', 'StreamingMovies'\n",
    "                ,'PaperlessBilling','PaymentMethod','item1', 'item2','item3','item4'\n",
    "                ,'item5','item6','item7','item8']\n",
    "\n",
    "# Create list of columns to include in PCA Analysis\n",
    "for col in df.columns:\n",
    "    list.append(col)\n",
    "for item in nonList:\n",
    "    list.remove(item)\n",
    "print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Unnamed: 0','CaseOrder','Customer_id','Interaction','City', \n",
    "                'State','County','Zip','Lat','Lng','Area',\n",
    "                'Timezone','Job','Education','Employment','Marital',\n",
    "                'Gender','Churn','Techie','Contract','Port_modem'\n",
    "                ,'Tablet','InternetService','Phone','Multiple','OnlineSecurity'\n",
    "                ,'OnlineBackup','DeviceProtection','TechSupport', 'StreamingTV', 'StreamingMovies'\n",
    "                ,'PaperlessBilling','PaymentMethod','item1', 'item2','item3','item4'\n",
    "                ,'item5','item6','item7','item8'],axis=1)\n",
    "pca = PCA()\n",
    "df_pca = pca.fit_transform(X=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of PCA Loading Matrix\n",
    "df_pca = pd.DataFrame(df_pca)\n",
    "df_pca.round(2).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca_loadings = pd.DataFrame(pca.components_)\n",
    "df_pca_loadings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = X - X.mean()\n",
    "X_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_.round(2)[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_exp_cumsum = pca.explained_variance_ratio_.cumsum().round(2)\n",
    "fig, axes = plot.subplots(1,1,figsize=(16,7), dpi=100)\n",
    "plot.plot(variance_exp_cumsum, color='firebrick')\n",
    "plot.title('Screeplot of Variance Explained %', fontsize=22)\n",
    "plot.xlabel('# of PCs', fontsize=16)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html (READING CSV WITH PANDAS)\n",
    "2. https://medium.com/ydata-ai/auditing-data-quality-with-pandas-profiling-b1bf1919f856 (ASSESSING DATA QUALITY WITH PYTHON )\n",
    "3. https://pypi.org/project/pandas-profiling/ (FIXING PANDAS_PROFILING IMPORT ERROR)\n",
    "4. https://medium.com/ydata-ai/auditing-data-quality-with-pandas-profiling-b1bf1919f856 (PANDAS DATA PROFILING LIBRARY)\n",
    "5. https://ipywidgets.readthedocs.io/en/stable/user_install.html (Activating Widgets In Jupyter Notebook Enviroment)\n",
    "6. https://www.oreilly.com/content/introducing-pandas-objects/#:~:text=Introducing%20Pandas%20Objects%201%20Pandas%20Series%20A%20pandas,...%208%20Constructing%20DataFrame%20Objects%20...%20More%20items (Explanation of different objects used in the pandas library)\n",
    "7. https://westerngovernorsuniversity.sharepoint.com/sites/DataScienceTeam/Shared%20Documents/Forms/AllItems.aspx?id=%2Fsites%2FDataScienceTeam%2FShared%20Documents%2FGraduate%20Team%2FD206%2FStudent%20Facing%20Resources%2FD206%20%2D%20Getting%20Started%20with%20D206%20Video%20Series%20%28Slides%20and%20Videos%29%2F3%2E%20D206%2DGettingStartedWithDuplicates%2Epdf&parent=%2Fsites%2FDataScienceTeam%2FShared%20Documents%2FGraduate%20Team%2FD206%2FStudent%20Facing%20Resources%2FD206%20%2D%20Getting%20Started%20with%20D206%20Video%20Series%20%28Slides%20and%20Videos%29 (Dealing with duplicate values)\n",
    "8. https://westerngovernorsuniversity.sharepoint.com/sites/DataScienceTeam/Shared%20Documents/Forms/AllItems.aspx?id=%2Fsites%2FDataScienceTeam%2FShared%20Documents%2FGraduate%20Team%2FD206%2FStudent%20Facing%20Resources%2FD206%20%2D%20Getting%20Started%20with%20D206%20Video%20Series%20%28Slides%20and%20Videos%29%2F6%2E%20D206%2DGettingStartedRexpressionofCategoricalVariables%2Epdf&parent=%2Fsites%2FDataScienceTeam%2FShared%20Documents%2FGraduate%20Team%2FD206%2FStudent%20Facing%20Resources%2FD206%20%2D%20Getting%20Started%20with%20D206%20Video%20Series%20%28Slides%20and%20Videos%29 (Norminal and Ordinal Encoding)\n",
    "9. https://www.machinelearningplus.com/machine-learning/principal-components-analysis-pca-better-explained/ (Principal Component Analysis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
